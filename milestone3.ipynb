{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee378b2c-20c8-48bd-9d47-e41c42dfeb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process the EU sustainable finance taxonomy PDF file and extract and clean all the paragraphs in the document\n"
     ]
    }
   ],
   "source": [
    "objective = 'Process the EU sustainable finance taxonomy PDF file and extract and clean all the paragraphs in the document'\n",
    "print(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e69435-bedf-4122-b5c1-4005d4fb9abb",
   "metadata": {},
   "source": [
    "### Extracting Paragraphs from the EU Taxonomy Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c989163-1808-47c3-bd55-94f7146180c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = r'https://lp-prod-resources.s3.us-west-2.amazonaws.com/214/200309-sustainable-finance-teg-final-report-taxonomy-annexes_en.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b8321-deac-45de-b06d-0ff817a58049",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d05580-f825-4b77-a58e-f3d90050aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textract\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4108e5-41bf-42e4-9b2b-e62c3e3b8b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"taxonamy.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c5320-6021-4bfe-8bf2-112347e88989",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(pdf_path)\n",
    "#filepath = os.path.join(\"PDFs\", filename)\n",
    "with open(filename, \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e46891-4d98-4f3a-8d88-2308c22cddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = textract.process(filename).decode('utf-8').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cfe3a4b-2f48-4860-b210-e0738257d7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1320993"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eb517cf-a3a6-48b4-adf8-56bdc24dcb6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Updated methodology & Updated Technical Screening Criteria\\n- 1-\\n\\nMarch 2020\\n\\n\\x0cAbout this report\\nThis document includes an updated Part B: Methodology from the June 2019 report and an updated Part\\nF: F'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84351af3-264d-4f44-a9d2-72d158f225f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ull list of technical screening criteria. The other original sections from the June 2019 report can be\\nfound as labelled in the June 2019 report.\\nPART A\\n\\nExplanation of the Taxonomy approach. This sec'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[200:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efde9bf8-d823-4333-b806-ea64f3a9d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = re.split(r\"\\s*?\\n\\s*?\\n\\s*?\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64736e75-ce5b-4efb-b48f-bfc09cc9271c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8983"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a3f138d-0c0b-4956-94e5-bf8712ddf2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Updated methodology & Updated Technical Screening Criteria\\n- 1-',\n",
       " 'March 2020',\n",
       " '\\x0cAbout this report\\nThis document includes an updated Part B: Methodology from the June 2019 report and an updated Part\\nF: Full list of technical screening criteria. The other original sections from the June 2019 report can be\\nfound as labelled in the June 2019 report.\\nPART A',\n",
       " 'Explanation of the Taxonomy approach. This section sets out the role and importance of\\nsustainable finance in Europe from a policy and investment perspective, the rationale for\\nthe development of an EU Taxonomy, the daft regulation and the mandate of the TEG.',\n",
       " 'PART B']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbc2f605-8593-4528-827d-cf9e98c5b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [p for p in paragraphs if len(p) > 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bea89bf-944e-41a8-b9cf-683f33b51bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1952"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b876ba6c-5ad8-4df2-be1b-05373d42f6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x0cAbout this report\\nThis document includes an updated Part B: Methodology from the June 2019 report and an updated Part\\nF: Full list of technical screening criteria. The other original sections from the June 2019 report can be\\nfound as labelled in the June 2019 report.\\nPART A',\n",
       " 'Explanation of the Taxonomy approach. This section sets out the role and importance of\\nsustainable finance in Europe from a policy and investment perspective, the rationale for\\nthe development of an EU Taxonomy, the daft regulation and the mandate of the TEG.',\n",
       " 'Methodology. This explains the methodologies for developing technical screening\\ncriteria for climate change mitigation objectives, adaptation objectives and ‘do no\\nsignificant harm’ to other environmental objectives in the legislative proposal.\\nThis has been updated since 2019.',\n",
       " 'Next steps for the Taxonomy. This section elaborates on unresolved issues and\\npotential ways forward for the Taxonomy and the technical work of the Platform on\\nSustainable Finance.',\n",
       " 'Full list of technical screening criteria. This annex sets out the sector- and\\neconomic activity-specific technical screening criteria and rationale for the TEG’s\\nanalysis. These have been updated since 2019.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e922153-1a5b-4955-9c4b-50a44c2397c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_paragraph(text):\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"  \", \" \").strip(\" \")\n",
    "    return re.sub(r'[^\\w\\s]', '', text).strip(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abcc01-9e3e-4ce0-a821-72e7715abb20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acdd8f8c-b553-4a6f-b6bd-ee5325585710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs = pd.DataFrame(paragraphs, columns=['paragraph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1270ed16-158b-4809-9eca-a7b974c6dcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About this report\\nThis document includes an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation of the Taxonomy approach. This sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Methodology. This explains the methodologies f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Next steps for the Taxonomy. This section elab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Full list of technical screening criteria. Thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  \n",
       "About this report\\nThis document includes an ...\n",
       "1  Explanation of the Taxonomy approach. This sec...\n",
       "2  Methodology. This explains the methodologies f...\n",
       "3  Next steps for the Taxonomy. This section elab...\n",
       "4  Full list of technical screening criteria. Thi..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraphs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "652eb043-4ce5-42ac-8bdb-6b89f9a83051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1952, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraphs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d89a7579-af3b-4df8-8feb-80ef91e61d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs = df_paragraphs['paragraph'].apply(clean_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f5363f9-3e26-4c95-8b86-ba88d387e2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \n",
       "About this report This document includes an u...\n",
       "1    Explanation of the Taxonomy approach This sect...\n",
       "2    Methodology This explains the methodologies fo...\n",
       "3    Next steps for the Taxonomy This section elabo...\n",
       "4    Full list of technical screening criteria This...\n",
       "Name: paragraph, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraphs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0ef6532-596d-4e33-9837-d8b2e308e34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1952,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paragraphs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc2f3a-82ac-4bb3-80b9-691dfb243a2a",
   "metadata": {},
   "source": [
    "### Question Paragraph Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e1efd2-1296-4b53-a6f4-380e0e04ca9d",
   "metadata": {},
   "source": [
    "#### Build a text vectorizer that finds the best matching paragraph for the provided set of questions and qualitatively evaluates the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "612ffe2a-2300-44bb-8240-7aba624233ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    [\"What fuel is used for manufacturing of chlorine?\"],\n",
    "    [\"What metric is used for evaluating emission?\"],\n",
    "    [\"How can carbon emission of the processes of cement clinker be reduced?\"],\n",
    "    [\"How is the Weighted Cogeneration Threshold calculated?\"],\n",
    "    [\"What is carbon capture and sequestration?\"],\n",
    "    [\"What stages does CCS consist of?\"],\n",
    "    [\"What should be the average energy consumption of a water supply system?\"],\n",
    "    [\"What are examples of sludge treatments?\"],\n",
    "    [\"How is the process of anaerobic digestion?\"],\n",
    "    [\"How is reforestation defined?\"],\n",
    "    [\"What is the threshold of emssion for inland passenger water transport?\"], \n",
    "    [\"What are the requirements of reporting for electricity generation from natural gas where there might be fugative emissions?\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0dafe8e-13d8-4dcc-9796-14d93ee8e19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What fuel is used for manufacturing of chlorine?']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0545277-df5a-452f-894c-15a2ef0b2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a017dbfa-b8c3-4be0-b800-ef0617eb2e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate a TF-IDF model trained on the paragraphs from the previous milestone by using the TfidfVectorizer class \n",
    "# from the scikit-learn library. \n",
    "#This model will provide a representation for each paragraph or each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53af18e1-1abd-4594-8c3c-35280d7dfbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1952, 6708)\n",
      "6708\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_paragraphs)\n",
    "tfidf_tokens = vectorizer.get_feature_names_out()\n",
    "#print(X)\n",
    "#print(vectorizer.get_feature_names_out())\n",
    "print(X.shape)\n",
    "print(len(tfidf_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7250f39f-381c-4333-b3ba-528c6d1c99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7da5449-c8c4-4673-bf83-6aa2f0e610de",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = []\n",
    "for q in questions:\n",
    "    vec = vectorizer.transform(q)\n",
    "    rank = linear_kernel(vec,X).flatten()\n",
    "    vecs.append((q,df_paragraphs[rank.argsort()[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21e22f17-6ad9-405c-9874-58b6f8b7cef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['How can carbon emission of the processes of cement clinker be reduced?'],\n",
       " 'Thresholds for cement Clinker A are applicable to plants that produce clinker only and do not produce finished cement All other plants need to meet the thresholds for cement or alternative binder A Cement clinker Specific emissions calculated according to the methodology used for EUETS benchmarks associated to the clinker production processes are lower than the value of the related EUETS benchmark As of February 2020 the EUETS benchmark value for cement clinker manufacturing is 0766 tCO2et of clinker198 B Cement Specific emissions associated to the clinker and cement production processes are lower than 0498 tCO2et of cement or alternative binder 199')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49f3b8cb-ae33-4140-9f29-f263c117a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"distilbert-base-uncased-distilled-squad\"\n",
    "TEST_SAMPLE_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "697ba15a-e3a2-4d06-a51c-db042a2cb366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/home/b635040c-829a-4f40-8689-9aa2d4dd8b8f/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('squad', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "70f5b08f-2913-44af-8fab-359e54afd5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#import json\n",
    "\n",
    "#with open(\"data/dev-v2.0.json\") as f:\n",
    "#    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ceb71d35-4649-4d8c-b47b-e2ec54ea4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qustion_answers_context(data):\n",
    "    # this function should provide tiples of quetion, answer and context from the data\n",
    "    #return data['question'], data['answers'], data['context']\n",
    "    ls = []\n",
    "    for row in data:\n",
    "        triple = row['question'], row['answers'], row['context']\n",
    "        ls.append(triple)\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0321a23f-986f-4c7b-9988-f30b43e895dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "qac = random.sample(get_qustion_answers_context(dataset), TEST_SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae8598ad-76d6-4709-89eb-e81601dc286f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 18:26:12.665190: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2023-10-30 18:26:12.920438: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2023-10-30 18:26:12.952029: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2023-10-30 18:26:16.127578: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2023-10-30 18:26:16.250061: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b058aada-d858-4fd0-81b7-1fc0226ece81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['1934'], 'answer_start': [53]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qac[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed09230c-6f75-4476-8049-256d57c96654",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = question_answerer(question=qac[0][0],     context=qac[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ca94b5b-7623-4c63-a395-0e037436dd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9913541078567505"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d8ac99b-5021-4f71-9ba3-830e7faf5373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_em_scores(qac, qa_model):\n",
    "    # This function should return a list of scores where it has gone through the triples of question, answer and contex and ran the model to see when it matches with the answer. \n",
    "    scores = []\n",
    "    for q in qac:\n",
    "        res = qa_model(question=q[0], context=q[2])\n",
    "        scores.append(res['score'])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b7268-27d6-42ff-a45b-3f9d7ba6e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_em_scores(qac,question_answerer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c5ec1991-0d86-4d44-9caf-8e40ce65f6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForQuestionAnswering.\n",
      "\n",
      "All the weights of TFDistilBertForQuestionAnswering were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForQuestionAnswering for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "question_answerer = pipeline(\"question-answering\", model=MODEL, tokenizer=MODEL, device=-1)\n",
    "\n",
    "\n",
    "def get_answer_pipeline(question, context):\n",
    "    result = question_answerer(auestion=question, context=context)\n",
    "    return answer[\"answer\"].rstrip(\".\").rstrip(\",\").lstrip(\"(\").rstrip(\")\").rstrip(\".\").strip(\"'\").strip(\":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "21dc9dbd-3893-44b5-94ed-4d1f598d3ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown arguments {'auestion': 'When did the first Archivist start at the National Archives?', 'context': 'The first Archivist, R.D.W. Connor, began serving in 1934, when the National Archives was established by Congress. As a result of a first Hoover Commission recommendation, in 1949 the National Archives was placed within the newly formed General Services Administration (GSA). The Archivist served as a subordinate official to the GSA Administrator until the National Archives and Records Administration became an independent agency on April 1, 1985.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m get_em_scores(qac, get_answer_pipeline)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(scores)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(scores))\n",
      "Cell \u001b[0;32mIn[80], line 5\u001b[0m, in \u001b[0;36mget_em_scores\u001b[0;34m(qac, qa_model)\u001b[0m\n\u001b[1;32m      3\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m qac:\n\u001b[0;32m----> 5\u001b[0m     res \u001b[38;5;241m=\u001b[39m qa_model(question\u001b[38;5;241m=\u001b[39mq[\u001b[38;5;241m0\u001b[39m], context\u001b[38;5;241m=\u001b[39mq[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      6\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "Cell \u001b[0;32mIn[82], line 6\u001b[0m, in \u001b[0;36mget_answer_pipeline\u001b[0;34m(question, context)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_answer_pipeline\u001b[39m(question, context):\n\u001b[0;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m question_answerer(auestion\u001b[38;5;241m=\u001b[39mquestion, context\u001b[38;5;241m=\u001b[39mcontext)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages/transformers/pipelines/question_answering.py:391\u001b[0m, in \u001b[0;36mQuestionAnsweringPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03mAnswer the question(s) given as inputs by using the context(s).\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    - **answer** (`str`) -- The answer to the question.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;66;03m# Convert inputs to features\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_parser(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(examples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages/transformers/pipelines/question_answering.py:202\u001b[0m, in \u001b[0;36mQuestionAnsweringArgumentHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be understood\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# When user is sending a generator we need to trust it's a valid example\u001b[39;00m\n\u001b[1;32m    205\u001b[0m generator_types \u001b[38;5;241m=\u001b[39m (types\u001b[38;5;241m.\u001b[39mGeneratorType, Dataset) \u001b[38;5;28;01mif\u001b[39;00m Dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (types\u001b[38;5;241m.\u001b[39mGeneratorType,)\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown arguments {'auestion': 'When did the first Archivist start at the National Archives?', 'context': 'The first Archivist, R.D.W. Connor, began serving in 1934, when the National Archives was established by Congress. As a result of a first Hoover Commission recommendation, in 1949 the National Archives was placed within the newly formed General Services Administration (GSA). The Archivist served as a subordinate official to the GSA Administrator until the National Archives and Records Administration became an independent agency on April 1, 1985.'}"
     ]
    }
   ],
   "source": [
    "scores = get_em_scores(qac, get_answer_pipeline)\n",
    "print(sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019262e5-f430-4eca-8585-8f267068431c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
